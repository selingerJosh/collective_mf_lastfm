import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from cmfrec import CMF_explicit
from cmfrec import MostPopular
from sklearn.model_selection import train_test_split
from time import time
import recmetrics as rm
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import scipy as sp
import ml_metrics as metrics
from statsmodels.stats.multicomp import (pairwise_tukeyhsd,
                                         MultiComparison)

################# raw import
df_user_artist = pd.read_csv("data/user_artists.dat", sep = '\\t', engine='python')

df_artist = pd.read_csv("data/artists.dat", sep = '\\t', engine='python')

df_user_taggedartist = pd.read_csv("data/user_taggedartists.dat", sep = '\\t', engine='python')

df_tag = pd.read_csv("data/tags.dat", sep = '\\t', engine='python')

df_user_friends = pd.read_csv("data/user_friends.dat", sep = '\\t', engine='python')

#################### one hot encode df_tag
df_one_hot_tagged = (df_user_taggedartist.groupby(['artistID', 'tagID'], as_index=False)
     .count()
     .pivot(index='artistID', columns='tagID', values='userID')
     .fillna(0)
     .astype(bool).astype(int)
 )


df_one_hot_tagged['ItemId'] = df_one_hot_tagged.index


df_one_hot_tagged

######################### transform social graph to adjacency matrix
df_user_friends['value'] = 1

df_friends_adjacent = (df_user_friends.groupby(['userID', 'friendID'], as_index=False)
 .count()
 .pivot(index='userID', columns='friendID', values='value')
 .fillna(0)
 )

df_friends_adjacent['UserId'] = df_friends_adjacent.index

########################## log transform user artist interactions
df_user_artist['weight_log'] = np.log(df_user_artist['weight'])

########################## give appropriate fields correct name for cmfrec
df_ratings = df_user_artist.drop('weight', axis = 1)
df_ratings.columns = ['UserId', 'ItemId', 'Rating' ]


############################# train val test split
df_ratings_train, df_ratings_test = train_test_split(df_ratings, test_size=0.2, random_state=100)
df_ratings_train, df_ratings_val = train_test_split(df_ratings_train, test_size=0.25, random_state= 100)

users_train = df_ratings_train['UserId'].unique()
items_train = df_ratings_train['ItemId'].unique()

ratings_val_users_items = df_ratings_val.loc[df_ratings_val['UserId'].isin(users_train) & df_ratings_val['ItemId'].isin(items_train)]
ratings_test_users_items = df_ratings_test.loc[df_ratings_test['UserId'].isin(users_train) & df_ratings_test['ItemId'].isin(items_train)]

df_user_side_train = df_friends_adjacent.loc[df_friends_adjacent['UserId'].isin(users_train)]
df_item_side_train = df_one_hot_tagged.loc[df_one_hot_tagged['ItemId'].isin(items_train)]

len(users_train), len(items_train)

(len(df_ratings_test) - len(ratings_test_users_items))/len(df_ratings_test)

#training val loop


#######mat fact
mf_results = []
loop_start = time()
for l in [1e-3,1e-2,1e-1,1e+1,1e+2]:
    for k in [20,30,40,50,60,70,80]:
                start = time()
                m_mf = CMF_explicit(k=k, lambda_=l ) \
                    .fit(X=df_ratings_train)
                fit_time = time() - start
                pred_train_col_mf = m_mf.predict(df_ratings_train['UserId'], df_ratings_train['ItemId'])
                mse_train_col_mf = rm.mse(df_ratings_train['Rating'], pred_train_col_mf)
                pred_val_col_mf = m_mf.predict(ratings_val_users_items['UserId'], ratings_val_users_items['ItemId'])
                mse_val_col_mf = rm.mse(ratings_val_users_items.Rating, pred_val_col_mf)
                result = [l, k, mse_train_col_mf, mse_val_col_mf, fit_time]
                print(result)
                mf_results.append(result)
loop_end = time()

test = pd.DataFrame(mf_results)
test = test.sort_values(by = 3, ascending=True)

#test.to_csv('mf_gridresult.csv')

######col mat fact
col_mf_results = []
loop_start = time()
for l in [1e-3,1e-2,1e-1,1e+1,1e+2]:
    for k in [20,30,40,50,60,70,80]:
        for w_u in [0.5,1]:
           for w_i in [0.5,1]:
               start = time()
               m_col_mf = CMF_explicit(k=k, lambda_=l, w_user=w_u, w_item=w_i ) \
                            .fit(X=df_ratings_train,
                                 U=df_user_side_train,
                                 I=df_item_side_train)
               fit_time = time() - start
               pred_train_col_mf = m_col_mf.predict(df_ratings_train['UserId'], df_ratings_train['ItemId'])
               mse_train_col_mf = rm.mse(df_ratings_train['Rating'], pred_train_col_mf)
               pred_val_col_mf = m_col_mf.predict(ratings_val_users_items['UserId'], ratings_val_users_items['ItemId'])
               mse_val_col_mf = rm.mse(ratings_val_users_items.Rating, pred_val_col_mf)
               result = [l, k, mse_train_col_mf, mse_val_col_mf, fit_time, w_u, w_i]
               print(result)
               col_mf_results.append(result)


loop_end = time()

test_col = pd.DataFrame(col_mf_results)
test_col = test_col.sort_values(by = 3, ascending=True)

#test_col.to_csv('col_mf_grid.csv')

############### results by cohort
m_col_mf = CMF_explicit(k=60, lambda_=10, user_bias=True, item_bias=True ).fit(X=df_ratings_train,U=df_user_side_train,I=df_item_side_train)

m_mf = CMF_explicit(k=80, lambda_=.1, user_bias=True, item_bias=True ).fit(X=df_ratings_train)

m_most_pop = MostPopular(implicit=False).fit(X=df_ratings_train)

pred_test_most_pop = m_most_pop.predict(ratings_test_users_items['UserId'], ratings_test_users_items['ItemId'])

pred_test_col_mf = m_col_mf.predict(ratings_test_users_items['UserId'], ratings_test_users_items['ItemId'])

pred_test_mf = m_mf.predict(ratings_test_users_items['UserId'], ratings_test_users_items['ItemId'])


#seen in training set


rm.mse(ratings_test_users_items['Rating'], pred_test_most_pop)
rm.mse(ratings_test_users_items['Rating'], pred_test_col_mf)
rm.mse(ratings_test_users_items['Rating'], pred_test_mf)
###############################long tail plot


#######generate coverage for each model
def get_pred_recommendations(fitted_model, dataset = df_ratings_test):
    all_recs = []
    for i in dataset['UserId'].sort_values():
        rec = list(fitted_model.topN(i))
        all_recs.append(rec)
    return  all_recs

col_mf_recs = get_pred_recommendations(m_col_mf)
mf_recs = get_pred_recommendations(m_mf)
mostpop_recs = get_pred_recommendations(m_most_pop)

rm.prediction_coverage(col_mf_recs, list(df_user_artist['artistID'].unique()))
rm.prediction_coverage(mf_recs, list(df_user_artist['artistID'].unique()))
rm.prediction_coverage(mostpop_recs, list(df_user_artist['artistID'].unique()))

len(df_ratings_train['ItemId'].unique())
len(list(df_user_artist['artistID'].unique()))
#################################
true_rank_listens = (df_ratings_test
    .sort_values(by = ['UserId', 'Rating'], ascending=[True,False])
    .groupby('UserId')['ItemId']
    .apply(list))


################################# f test

rm.mse(ratings_test_users_items['Rating'], pred_test_most_pop)
rm.mse(ratings_test_users_items['Rating'], pred_test_col_mf)
rm.mse(ratings_test_users_items['Rating'], pred_test_mf)

most_pop_e2 =(ratings_test_users_items['Rating'] - pred_test_most_pop)**2
col_mf_e2 =(ratings_test_users_items['Rating'] - pred_test_col_mf)**2
mf_e2 =(ratings_test_users_items['Rating'] - pred_test_mf)**2

np.sqrt(np.mean(mf_e2))

sp.stats.f_oneway(most_pop_e2, col_mf_e2, mf_e2)

test_results = pd.DataFrame({'Bias Baseline':most_pop_e2,'Collective MF':col_mf_e2, 'MF':mf_e2}).stack().reset_index()
MultiComp = MultiComparison(test_results[0],
                            test_results['level_1'])
print(MultiComp.tukeyhsd().summary())

plt.rc('figure', figsize=(12, 7))
#plt.text(0.01, 0.05, str(model.summary()), {'fontsize': 12}) old approach
plt.text(0.01, 0.05, str(MultiComp.tukeyhsd().summary()), {'fontsize': 10}, fontproperties = 'monospace') # approach improved by OP -> monospace!
plt.axis('off')
plt.tight_layout()
plt.savefig('tukey.png')


################################ pca on user and item matrices
u_scaler = StandardScaler()
i_scaler = StandardScaler()

df_user_side_train_scaled = u_scaler.fit_transform(df_user_side_train.drop(columns = 'UserId'))
df_item_side_train_scaled = i_scaler.fit_transform(df_item_side_train.drop(columns = 'ItemId'))

u_pca = PCA()
i_pca = PCA()

user_side_train_pca = u_pca.fit_transform(df_user_side_train_scaled)
item_side_train_pca = i_pca.fit_transform(df_item_side_train_scaled)

df_user_side_train_pca = pd.DataFrame(user_side_train_pca)
df_user_side_train_pca['UserId'] = df_user_side_train['UserId']

df_item_side_train_pca = pd.DataFrame(item_side_train_pca)
df_item_side_train_pca['ItemId'] = df_item_side_train['ItemId']

user_side_train_pca.shape

df_user_side_train_pca.shape
df_item_side_train_pca.shape


df_user_side_train.shape
df_item_side_train.shape

################################ modelling testing

non_start = time()
m_col_mf_test = CMF_explicit(lambda_=10) \
                    .fit(X=df_ratings_train,
                         U=df_user_side_train,
                         I=df_item_side_train)
non_time = time() - non_start

pred_val_col_mf_raw = m_col_mf_test.predict(ratings_val_users_items['UserId'], ratings_val_users_items['ItemId'])

print(rm.mse(ratings_val_users_items['Rating'], pred_val_col_mf_raw))

pca_start = time()
m_col_mf_pca = CMF_explicit(lambda_=10) \
                    .fit(X=df_ratings_train,
                         U=df_user_side_train_pca,
                         I=df_item_side_train_pca)

pca_time = time() - pca_start

pred_val_col_mf_pca = m_col_mf_pca.predict(ratings_val_users_items['UserId'], ratings_val_users_items['ItemId'])

print(rm.mse(ratings_val_users_items['Rating'], pred_val_col_mf_pca))


